{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Recommender Systems for Comrade Platform\n",
                "\n",
                "This notebook develops lightweight recommender systems for various platform content.\n",
                "\n",
                "## Models\n",
                "1. **Collaborative Filtering** - Matrix factorization for user-item interactions\n",
                "2. **Content-Based** - TF-IDF + cosine similarity\n",
                "3. **Hybrid** - LightGBM ranking model\n",
                "\n",
                "## Content Types\n",
                "- Opinions (posts)\n",
                "- Articles\n",
                "- Research\n",
                "- Events\n",
                "- Rooms\n",
                "- People (connections)\n",
                "- Organizations\n",
                "- Products"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install pandas numpy scikit-learn lightgbm scipy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy.sparse import csr_matrix\n",
                "from scipy.sparse.linalg import svds\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.model_selection import train_test_split\n",
                "import lightgbm as lgb\n",
                "from collections import defaultdict"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Collaborative Filtering with SVD"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CollaborativeFilter:\n",
                "    \"\"\"\n",
                "    Simple SVD-based collaborative filtering.\n",
                "    Efficient for medium-sized datasets.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, n_factors=50):\n",
                "        self.n_factors = n_factors\n",
                "        self.user_factors = None\n",
                "        self.item_factors = None\n",
                "        self.user_mapping = {}\n",
                "        self.item_mapping = {}\n",
                "        self.mean_rating = 0\n",
                "    \n",
                "    def fit(self, interactions_df):\n",
                "        \"\"\"\n",
                "        Fit the model on user-item interactions.\n",
                "        \n",
                "        Args:\n",
                "            interactions_df: DataFrame with columns [user_id, item_id, interaction]\n",
                "        \"\"\"\n",
                "        # Create mappings\n",
                "        users = interactions_df['user_id'].unique()\n",
                "        items = interactions_df['item_id'].unique()\n",
                "        \n",
                "        self.user_mapping = {u: i for i, u in enumerate(users)}\n",
                "        self.item_mapping = {i: j for j, i in enumerate(items)}\n",
                "        self.reverse_item_mapping = {j: i for i, j in self.item_mapping.items()}\n",
                "        \n",
                "        # Create sparse matrix\n",
                "        rows = interactions_df['user_id'].map(self.user_mapping)\n",
                "        cols = interactions_df['item_id'].map(self.item_mapping)\n",
                "        vals = interactions_df['interaction']\n",
                "        \n",
                "        self.mean_rating = vals.mean()\n",
                "        matrix = csr_matrix((vals - self.mean_rating, (rows, cols)))\n",
                "        \n",
                "        # SVD decomposition\n",
                "        U, sigma, Vt = svds(matrix.astype(float), k=min(self.n_factors, min(matrix.shape) - 1))\n",
                "        \n",
                "        self.user_factors = U * np.sqrt(sigma)\n",
                "        self.item_factors = Vt.T * np.sqrt(sigma)\n",
                "        \n",
                "        return self\n",
                "    \n",
                "    def recommend(self, user_id, n=10, exclude_seen=True):\n",
                "        \"\"\"\n",
                "        Get top-N recommendations for a user.\n",
                "        \"\"\"\n",
                "        if user_id not in self.user_mapping:\n",
                "            return []  # Cold start - return popular items\n",
                "        \n",
                "        user_idx = self.user_mapping[user_id]\n",
                "        scores = np.dot(self.user_factors[user_idx], self.item_factors.T) + self.mean_rating\n",
                "        \n",
                "        # Get top indices\n",
                "        top_indices = np.argsort(scores)[::-1][:n * 2]  # Get extra for filtering\n",
                "        \n",
                "        recommendations = []\n",
                "        for idx in top_indices:\n",
                "            if len(recommendations) >= n:\n",
                "                break\n",
                "            item_id = self.reverse_item_mapping[idx]\n",
                "            recommendations.append({\n",
                "                'item_id': item_id,\n",
                "                'score': float(scores[idx])\n",
                "            })\n",
                "        \n",
                "        return recommendations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Content-Based Filtering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ContentBasedFilter:\n",
                "    \"\"\"\n",
                "    TF-IDF based content similarity.\n",
                "    Works well for text content (articles, opinions).\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, max_features=5000):\n",
                "        self.vectorizer = TfidfVectorizer(\n",
                "            max_features=max_features,\n",
                "            stop_words='english',\n",
                "            ngram_range=(1, 2)\n",
                "        )\n",
                "        self.item_vectors = None\n",
                "        self.item_ids = None\n",
                "    \n",
                "    def fit(self, items_df):\n",
                "        \"\"\"\n",
                "        Fit on item content.\n",
                "        \n",
                "        Args:\n",
                "            items_df: DataFrame with columns [item_id, content]\n",
                "        \"\"\"\n",
                "        self.item_ids = items_df['item_id'].values\n",
                "        self.item_vectors = self.vectorizer.fit_transform(items_df['content'])\n",
                "        return self\n",
                "    \n",
                "    def similar_items(self, item_id, n=10):\n",
                "        \"\"\"\n",
                "        Find similar items based on content.\n",
                "        \"\"\"\n",
                "        idx = np.where(self.item_ids == item_id)[0]\n",
                "        if len(idx) == 0:\n",
                "            return []\n",
                "        \n",
                "        idx = idx[0]\n",
                "        item_vector = self.item_vectors[idx]\n",
                "        similarities = cosine_similarity(item_vector, self.item_vectors).flatten()\n",
                "        \n",
                "        # Get top indices (excluding self)\n",
                "        top_indices = np.argsort(similarities)[::-1][1:n+1]\n",
                "        \n",
                "        return [\n",
                "            {'item_id': self.item_ids[i], 'score': float(similarities[i])}\n",
                "            for i in top_indices\n",
                "        ]\n",
                "    \n",
                "    def recommend_for_user(self, user_history_ids, n=10):\n",
                "        \"\"\"\n",
                "        Recommend based on user's interaction history.\n",
                "        \"\"\"\n",
                "        if not user_history_ids:\n",
                "            return []\n",
                "        \n",
                "        # Get indices of user's items\n",
                "        indices = []\n",
                "        for item_id in user_history_ids:\n",
                "            idx = np.where(self.item_ids == item_id)[0]\n",
                "            if len(idx) > 0:\n",
                "                indices.append(idx[0])\n",
                "        \n",
                "        if not indices:\n",
                "            return []\n",
                "        \n",
                "        # Average user's item vectors\n",
                "        user_profile = self.item_vectors[indices].mean(axis=0)\n",
                "        similarities = cosine_similarity(user_profile, self.item_vectors).flatten()\n",
                "        \n",
                "        # Exclude already seen\n",
                "        for idx in indices:\n",
                "            similarities[idx] = -1\n",
                "        \n",
                "        top_indices = np.argsort(similarities)[::-1][:n]\n",
                "        \n",
                "        return [\n",
                "            {'item_id': self.item_ids[i], 'score': float(similarities[i])}\n",
                "            for i in top_indices\n",
                "        ]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hybrid Recommender with LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class HybridRecommender:\n",
                "    \"\"\"\n",
                "    LightGBM-based ranking model.\n",
                "    Combines collaborative and content features.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.model = None\n",
                "        self.collab_filter = CollaborativeFilter()\n",
                "        self.content_filter = ContentBasedFilter()\n",
                "    \n",
                "    def prepare_features(self, user_id, item_id, items_df):\n",
                "        \"\"\"\n",
                "        Create feature vector for user-item pair.\n",
                "        \"\"\"\n",
                "        features = []\n",
                "        \n",
                "        # Collaborative score\n",
                "        collab_score = 0\n",
                "        if user_id in self.collab_filter.user_mapping:\n",
                "            recs = self.collab_filter.recommend(user_id, n=100)\n",
                "            for rec in recs:\n",
                "                if rec['item_id'] == item_id:\n",
                "                    collab_score = rec['score']\n",
                "                    break\n",
                "        features.append(collab_score)\n",
                "        \n",
                "        # Item popularity (could be pre-computed)\n",
                "        features.append(0)  # Placeholder for popularity\n",
                "        \n",
                "        # User activity level\n",
                "        features.append(0)  # Placeholder for user activity\n",
                "        \n",
                "        # Recency (days since item created)\n",
                "        features.append(0)  # Placeholder\n",
                "        \n",
                "        return features\n",
                "    \n",
                "    def fit(self, interactions_df, items_df):\n",
                "        \"\"\"\n",
                "        Train the hybrid model.\n",
                "        \"\"\"\n",
                "        # First fit base models\n",
                "        self.collab_filter.fit(interactions_df)\n",
                "        self.content_filter.fit(items_df)\n",
                "        \n",
                "        # Prepare training data\n",
                "        # This would normally use actual interaction data\n",
                "        print(\"Hybrid model training placeholder\")\n",
                "        \n",
                "        return self"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Platform-Specific Recommenders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PlatformRecommender:\n",
                "    \"\"\"\n",
                "    Unified recommender for all platform content types.\n",
                "    \"\"\"\n",
                "    \n",
                "    CONTENT_TYPES = [\n",
                "        'opinions', 'articles', 'research', 'events',\n",
                "        'rooms', 'people', 'organizations', 'products',\n",
                "        'payment_groups', 'tasks', 'resources'\n",
                "    ]\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.recommenders = {}\n",
                "    \n",
                "    def train_for_content_type(self, content_type, interactions_df, items_df):\n",
                "        \"\"\"\n",
                "        Train a recommender for a specific content type.\n",
                "        \"\"\"\n",
                "        if content_type not in self.CONTENT_TYPES:\n",
                "            raise ValueError(f\"Unknown content type: {content_type}\")\n",
                "        \n",
                "        recommender = HybridRecommender()\n",
                "        recommender.fit(interactions_df, items_df)\n",
                "        self.recommenders[content_type] = recommender\n",
                "        \n",
                "        return self\n",
                "    \n",
                "    def get_recommendations(self, user_id, content_type, n=10):\n",
                "        \"\"\"\n",
                "        Get recommendations for a user.\n",
                "        \"\"\"\n",
                "        if content_type not in self.recommenders:\n",
                "            return {'error': f'No recommender trained for {content_type}'}\n",
                "        \n",
                "        recommender = self.recommenders[content_type]\n",
                "        return recommender.collab_filter.recommend(user_id, n=n)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Quick Demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample data\n",
                "np.random.seed(42)\n",
                "\n",
                "# Sample interactions\n",
                "n_users = 100\n",
                "n_items = 50\n",
                "n_interactions = 500\n",
                "\n",
                "sample_interactions = pd.DataFrame({\n",
                "    'user_id': np.random.randint(0, n_users, n_interactions),\n",
                "    'item_id': np.random.randint(0, n_items, n_interactions),\n",
                "    'interaction': np.random.randint(1, 6, n_interactions)  # 1-5 rating\n",
                "})\n",
                "\n",
                "# Sample items\n",
                "sample_items = pd.DataFrame({\n",
                "    'item_id': range(n_items),\n",
                "    'content': [f'Sample content for item {i}. This is placeholder text.' for i in range(n_items)]\n",
                "})\n",
                "\n",
                "print(f\"Sample data: {len(sample_interactions)} interactions, {n_items} items\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train collaborative filter\n",
                "cf = CollaborativeFilter(n_factors=20)\n",
                "cf.fit(sample_interactions)\n",
                "\n",
                "# Get recommendations\n",
                "recs = cf.recommend(user_id=0, n=5)\n",
                "print(\"Collaborative Filter Recommendations for User 0:\")\n",
                "for rec in recs:\n",
                "    print(f\"  Item {rec['item_id']}: {rec['score']:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train content filter\n",
                "cbf = ContentBasedFilter()\n",
                "cbf.fit(sample_items)\n",
                "\n",
                "# Get similar items\n",
                "similar = cbf.similar_items(item_id=0, n=5)\n",
                "print(\"\\nSimilar Items to Item 0:\")\n",
                "for item in similar:\n",
                "    print(f\"  Item {item['item_id']}: {item['score']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Export for Production"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "\n",
                "# Save models\n",
                "# joblib.dump(cf, '../models/recommenders/collab_filter.pkl')\n",
                "# joblib.dump(cbf, '../models/recommenders/content_filter.pkl')\n",
                "\n",
                "print(\"\\nModel export code ready!\")\n",
                "print(\"Recommender system development complete.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}